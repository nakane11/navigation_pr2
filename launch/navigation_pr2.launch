<launch>
  <arg name="use_vosk" default="false" doc="Use ros_vosk for speech recognition" />
  <arg name="use_speaker" default="true" doc="Enable robot speaking" />

  <include file="$(find navigation_pr2)/launch/speech_recognition.launch" >
    <arg name="use_vosk" value="$(arg use_vosk)" />
  </include>

  <group if="$(arg use_speaker)">
    <node name="speak_node"
          pkg="navigation_pr2" type="speak.py"
          respawn="true" >
    </node>
  </group>

  <node pkg="roseus" type="roseus" name="spot_map_server" output="screen"
        args="$(find navigation_pr2)/euslisp/spot-map-server.l" >
    <param name="robot" value="pr2"/>
  </node>
  
  <node name="republish_conversation"
        pkg="navigation_pr2" type="republish_conversation.py"
        output="screen"
        clear_params="true" >
    <remap from="~input1" to="/Tablet/voice" />
    <!-- <remap from="~input2" to="/robotsound_jp/goal" />  -->
    <remap from="~input2" to="/speak_node/say" />
    <rosparam>
      number_of_input: 2
      input1_transform: "m.transcript[0]"
      input1_color: "red"
      input1_speaker: "people"
      <!-- input2_transform: "m.goal.sound_request.arg" -->
      <!-- input2_color: "white" -->
      input2_transform: "m.data"
      input2_color: "white"
      input2_speaker: "PR2"
    </rosparam>
  </node>

</launch>
