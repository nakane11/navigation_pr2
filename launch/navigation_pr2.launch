<launch>
  <arg name="use_vosk" default="false" doc="Use ros_vosk for speech recognition" />
  <arg name="speaker_volume" default="1.0" doc="robot speaking volume" />
  <arg name="INPUT_IMAGE" default="/kinect_head/rgb/image_rect_color" />
  <arg name="INPUT_DEPTH_IMAGE" default="/kinect_head/depth_registered/hw_registered/image_rect" />
  <arg name="INPUT_CAMERA_INFO" default="/kinect_head/rgb/camera_info" />
  <arg name="inside_pr2" default="false" />

  <include file="$(find navigation_pr2)/launch/speech_recognition.launch" >
    <arg name="use_vosk" value="$(arg use_vosk)" />
  </include>

  <include file="$(find virtual_force_drag)/launch/pr2_lead.launch" />

  <include file="$(find teach_spot)/launch/human_filter_pr2.launch" />

  <include file="$(find navigation_utils)/launch/tf_transposer.launch" />

  <group if="$(arg inside_pr2)" >

    <node name="spot_map_server"
          pkg="navigation_pr2_nx" type="spot_map_server.py"
          output="screen"
          clear_params="true" >
    </node>

    <node name="republish_marker_array"
          pkg="navigation_pr2_3rdparty" type="republish_marker_array.py"
          output="screen" respawn="true"
          clear_params="true" >
      <remap from="~input" to="/spot_map_server/nodes" />
      <remap from="~output" to="/spot_map_server/nodes_republish" />
    </node>

  </group>

  <group unless="$(arg inside_pr2)" >

    <include file="$(find jsk_perception)/launch/hand_pose_estimation_2d.launch">
      <arg name="gui" value="false" />
      <arg name="gpu" value="-1" />
      <arg name="INPUT_IMAGE" value="$(arg INPUT_IMAGE)" />
      <arg name="INPUT_DEPTH_IMAGE" value="$(arg INPUT_DEPTH_IMAGE)" />
      <arg name="INPUT_CAMERA_INFO" value="$(arg INPUT_CAMERA_INFO)" />
      <arg name="with_depth" value="true" />
    </include>

    <node name="spot_map_server"
          pkg="navigation_pr2" type="spot_map_server.py"
          output="screen"
          clear_params="true" >
    </node>

    <node name="republish_marker_array"
          pkg="navigation_pr2" type="republish_marker_array.py"
          output="screen"
          clear_params="true" >
      <remap from="~input" to="/spot_map_server/nodes" />
      <remap from="~output" to="/spot_map_server/nodes_republish" />
    </node>

  </group>

  <node name="speak_node"
        pkg="navigation_pr2" type="speak.py"
        respawn="true" >
    <rosparam subst_value="true">
      volume: $(arg speaker_volume)
    </rosparam>
  </node>

  <node name="map_manager"
        pkg="navigation_pr2" type="map_manager.py"
        output="screen"
        clear_params="true" >
  </node>

  <node pkg="roseus" type="roseus" name="move_wrist" respawn="true"
        args="$(find navigation_pr2)/euslisp/holding-hand.l" >
  </node>

  <node name="republish_conversation"
        pkg="navigation_pr2" type="republish_conversation.py"
        output="screen" respawn="true"
        clear_params="true" >
    <remap from="~input1" to="/Tablet/voice" />
    <!-- <remap from="~input2" to="/robotsound_jp/goal" />  -->
    <remap from="~input2" to="/speak_node/say/goal" />
    <rosparam>
      number_of_input: 2
      input1_transform: "m.transcript[0]"
      input1_color: "red"
      input1_speaker: "people"
      <!-- input2_transform: "m.goal.sound_request.arg" -->
      <!-- input2_color: "white" -->
      input2_transform: "m.goal.data"
      input2_color: "white"
      input2_speaker: "PR2"
    </rosparam>
  </node>

  
</launch>
